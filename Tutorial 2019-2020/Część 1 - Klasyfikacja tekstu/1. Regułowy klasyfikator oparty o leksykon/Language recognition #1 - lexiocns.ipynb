{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Language #1 - lexiocns.ipynb","provenance":[{"file_id":"1pGXCJ6hpXwLNZPLfQ3cMNyYLybXuW6WF","timestamp":1577387733127}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"N1HcVB-8aGxJ","colab_type":"text"},"source":["Przed użyciem dodaj pliki:\n","*   *'dokument.txt'* (dokument do klasyfikacji)\n","*   folder *'language_lexicons'* z plikami z listami słów (np. *'english.txt'*)"]},{"cell_type":"code","metadata":{"id":"PKnocO_c53gK","colab_type":"code","colab":{}},"source":["import glob\n","\n","path = '/content/language_lexicons'\n","\n","files = [f for f in glob.glob(path + \"**/*.txt\", recursive=True)]\n","lexicons_words = []\n","lexicon_languages = []\n","lexicons = []\n","\n","for languageFile in files:\n","  with open(languageFile, 'r') as openFile:\n","    file_text = openFile.read(10**9)\n","    lexicons_words.append(file_text)\n","    lexicon_languages.append(languageFile[:-4].replace(\"/content/language_lexicons/\",\"\"))\n","    lexicons.append(file_text.split(\" \"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCrWqDqe6D0Y","colab_type":"code","colab":{}},"source":["document_path = '/content/document.txt'\n","\n","with open(document_path, 'r') as doc:\n","  doc_text = doc.read(10**9)\n","\n","doc_text_words = doc_text.split()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fe7-W_Tf9SzI","colab_type":"code","colab":{}},"source":["word_frequency = [0 for l in lexicons]\n","\n","for word in doc_text_words:\n","  possibilities = 0\n","  for lexicon in lexicons:\n","    if(word in lexicon):\n","      possibilities+=(1.5*len(lexicon) - lexicon.index(word))\n","  for i in range(len(lexicons)):\n","    if(word in lexicons[i]):\n","      lexicon = lexicons[i]\n","      word_frequency[i] = word_frequency[i]+((1.5*len(lexicon) - lexicon.index(word))/possibilities)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAa-BWMB_Cz0","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def softmax(x):\n","    return np.exp(x) / np.sum(np.exp(x), axis=0)\n","\n","language_probabilities = list(softmax(word_frequency))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R93gSkWQJoy9","colab_type":"code","colab":{}},"source":["word_frequencies_repaired = []\n","for el in word_frequency:\n","  word_frequencies_repaired.append(el*100/np.sum(word_frequency, axis=0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YLGyQEjSBfqU","colab_type":"code","outputId":"56d42a6e-8781-42a1-ba6a-108d50bb07bf","executionInfo":{"status":"ok","timestamp":1577032137485,"user_tz":-60,"elapsed":2044,"user":{"displayName":"Dawid Ratyński","photoUrl":"","userId":"16936771803985771693"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["print(\"Normal probabilities:\")\n","for i in range(len(lexicon_languages)):\n","  language = lexicon_languages[i]\n","  print(\"Possibility of: \"+language+\" is about \"+str(int(word_frequencies_repaired[i] * 100)/100)+\"%\")\n","\n","print(\"\\nSoftmaxed probabilities:\")\n","for i in range(len(lexicon_languages)):\n","  language = lexicon_languages[i]\n","  print(\"Possibility of: \"+language+\" is about \"+str(int(language_probabilities[i] * 10000)/100) + \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Normal probabilities:\n","Possibility of: russian is about 0.0%\n","Possibility of: english is about 12.19%\n","Possibility of: spanish is about 6.78%\n","Possibility of: french is about 4.31%\n","Possibility of: polish is about 76.7%\n","\n","Softmaxed probabilities:\n","Possibility of: russian is about 0.0%\n","Possibility of: english is about 0.0%\n","Possibility of: spanish is about 0.0%\n","Possibility of: french is about 0.0%\n","Possibility of: polish is about 99.99%\n"],"name":"stdout"}]}]}